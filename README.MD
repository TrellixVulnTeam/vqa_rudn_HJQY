# VQA by [LXMERT](https://github.com/airsplay/lxmert)

## Требуемый контент

Нужно перейти по [ссылке](https://drive.google.com/drive/folders/1Gq1uLUk6NdD0CcJOptXjxE6ssY5XAuat)
и скачать следующие файлы:
- `lxmert_data/snap/pretrained/model_LXRT.pth` в `./snap/pretrained/model_LXRT.pth`
- `lxmert_data/image_feature_zips/mscoco_imgfeat.zip`, разархивировать в `./data/mscoco_imgfeat/*.tsv`
- `lxmert_data/data/vqa/*.json` в `./data/vqa/*.json`

# Структура проекта

## Файловая структура

```
.
├───data # Датасеты и данные
│   ├───lxmert # Дополнительный список ответов TODO: Уточнить, для чего он нужен
│   ├───mscoco_imgfeat # Датасет размеченных изображений с их features
│   └───vqa # Датасет вопросов-ответов
├───snap # Вывод
│   ├───pretrained # Pre-trained основа LXRT
│   └───vqa # Вывод finetune и predict
└───src # Код
    ├───lxrt # Реализация основных подмоделей нейросети, оптимизации, токенизации
    ├───pretrain # Загрузка и восстановление весов QA сети
    ├───tasks # Точки входа в проект
    └───vqa # Основная логика проекта
```

## Зависимости модулей

![](assets/dependency_diagram.png)

## Диаграмма основной нейросети

![](assets/net_diagram.png)

## Описание модулей

### [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)

`nn.Module` из torch - это базовый класс всех модулей нейронной сети. 
Он реализует определение каждого уровня сети, а также механизм прямого вычисления 
и обратного распространения в классе (метод вычисления градиента, который используется 
при обновлении весов многослойного перцептрона - модели восприятия информации мозгом)

```py
# VQA Answer heads 
self.logit_fc = nn.Sequential(
    nn.Linear(hid_dim, hid_dim * 2), 
    GeLU(), BertLayerNorm(hid_dim * 2, eps=1e-12), 
    nn.Linear(hid_dim * 2, num_answers) 
)
```

Выше представлено создание секвинциальной/последовательной модели, состоящей из 4 слоёв, описанных ниже

### [nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)

Контейнер `nn.Sequential` (наследующий `nn.Module`) представляет собой хранение в каскадном виде, 
в данном случае результаты _(выходные данные)_ первого слоя будут передаваться на второй слой, 
результаты второго слоя – на третий и так по аналогии. Эта каскадность пути и отличает 
`nn.Sequential` от `nn.ModuleList`, который является именно контейнером для хранения _«Модулей»_

### [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)
`nn.Linear` – слой, на котором происходит линейная трансформация данных по формуле 
![linear_formula.gif](https://latex.codecogs.com/gif.latex?y%20%3D%20xA%5E%7BT%7D%20&plus;%20b). 
Входными аргументами являются in_features – размер каждого входного экземпляра, 
out_features – размер каждого выходного экземпляра, bias – True или False, по умолчанию истина, 
что означает что будет происходить вычисление смещения. 
Атрибуты экземпляра данного класса: weight – обучаемые веса модуля фигуры 
(экземпляр класса nn.Parameter, наследующего tourch.Tensor), 
bias – обучаемые смещения модуля фигуры (экземпляр класса nn.Parameter, наследующего tourch.Tensor)

### [GeLU](https://paperswithcode.com/method/gelu) 

**GeLU** _(Gaussian Error Linear Units)_ – функция активации, служит активацией по умолчанию для таких моделей, как BERT. 
Смотря на график для гауссовой погрешности линейной единицы, можно сказать, что он имеет отрицательный коэффициент, 
который смещается в положительный коэффициент. Когда x больше нуля, выходное значение будет равно x, 
за исключением случаев, когда x = 0 до x = 1, где он слегка наклоняется к меньшему значению y.
Эта функция позволяет предотвращать проблему исчезающих градиентов.
[(реализация)](https://github.com/ZONT3/vqa_rudn/blob/0c14996d2184ecf1ec0dfffbabd1d8b29faf7e78/src/lxrt/modeling.py#L122)

![gelu_graph.png](assets/gelu_graph.png)

### BertLayerNorm

**BertLayerNorm** – слой нормализации, предназначенный для сокращения времени обучения путём нормализации деятельности 
нейронов, с помощью результатов вычисления таких величин как: среднего значения, дисперсии, стандартного отклонения, 
используемых для нормализации данных. Этот уровень использует статистику, вычисленную на основе входных данных, 
как в режиме обучения (`training`), так и в режиме оценки (`evaluation`). 
Аргументы конструктора класса: `normalized_shape` (целое число (`int`) или список (`list`) или `torch.Size`) - форма ввода 
из ожидаемого ввода размера (если используется одно целое число, оно обрабатывается как одноэлементный список, 
и этот модуль будет нормализован по последнему измерению, которое, как ожидается, будет иметь этот 
конкретный размер), eps - значение, добавляемое к знаменателю для числовой стабильности (по умолчанию это 1e-5), 
но в нашем случае задано `1е-12`, `elementwise_affine` - логическое значение, по умолчанию `True`, 
в таком случае в этом блоке есть обучаемые аффинные параметры для каждого элемента, инициализированные единицами 
(для весов) и нулями (для смещений). Сами аффинные преобразования изменяют геометрию плоскости, при этом сохраняя 
параллельность линий и соотношение расстояний. Это один из основных методов обработки изображений. Они используются 
для исправления искажений и деформаций, возникающих при не самых идеальных ракурсах камеры. 
Широко применяются в машинном обучении и компьютерном зрении. В основе метода аффинных преобразований лежит изменение 
единичной матрицы с учетом матриц масштабирования, перемещения, сдвига и поворота. 

В нашем случае:
`BertLayerNorm = `[torch.nn.LayerNorm](https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html)


